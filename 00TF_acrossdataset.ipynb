{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_utilize import Unicorn\n",
    "from OtherData_utilize import Physionet, BCIcompet2a\n",
    "\n",
    "target_class = [\"Left\", \"Right\", \"Non\", \"Feet\"]  #adjust selective classes\n",
    "num_subject_physionet = 109\n",
    "\n",
    "load_wLTL_weight = True  #saved weight of 109 physionet subject\n",
    "condition_wLTL = \"noEA\"\n",
    "EA_wLTL_weight = \"EA_wLTL_4class.pkl\"\n",
    "noEA_wLTL_weight = \"noEA_wLTL_4class.pkl\"\n",
    "\n",
    "AllBCIClass = Unicorn(selectclass = target_class, desired_fz = 128, ch_pick = ['Fz','C3','Cz','C4','Pz'])\n",
    "Class_compet = BCIcompet2a(selectclass = target_class, desired_fz = 128, ch_pick = ['EEG-Fz', 'EEG-Cz', 'EEG-C3', 'EEG-C4', 'EEG-Pz'])\n",
    "Class_Physio = Physionet(selectclass = target_class, desired_fz = 128, ch_pick =  ['Fz..','C3..', 'Cz..','C4..','Pz..'])\n",
    "\n",
    "target_data_0 = \"Kawin\" #this subject will be test_set otherwise are train_set\n",
    "calibrate_size = 80 # (trial)\n",
    "train_svm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicorn hybrid black dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful to create Data of ['Kawin']\n",
      "Used Annotations descriptions: ['OVTK_GDF_Cross_On_Screen', 'OVTK_GDF_Left', 'OVTK_GDF_Right', 'OVTK_GDF_Tongue', 'OVTK_GDF_Up']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\main_utilize.py:97: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].get_data()\n"
     ]
    }
   ],
   "source": [
    "subjectForTargetData = [target_data_0]\n",
    "EEG_data = AllBCIClass.GetRawEDF(target_subjects= subjectForTargetData, condition=\"Offline_Experiment\")\n",
    "Unicorn_Epochs = AllBCIClass.GetEpoch(EEG_data ,tmin= -2.0, tmax= 6.0, crop = (0,4) ,baseline= (-0.5,0.0), band_pass=(6,32),trial_removal_th = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCI Compettition 2a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '32766', '768', '769', '770', '771', '772']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n",
      "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:259: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    }
   ],
   "source": [
    "EEG_data = Class_compet.GetRaw(target_subjects=\"all\", preload=True)\n",
    "EEG_compet_Epochs = Class_compet.GetEpoch(EEG_data ,tmin= -1.0, tmax= 4.0, crop = (0,4) ,baseline=(-0.5,0.0),band_pass=(6,32),trial_removal_th = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physionet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subject number:  1\n",
      "processing subject number:  2\n",
      "processing subject number:  3\n",
      "processing subject number:  4\n",
      "processing subject number:  5\n",
      "processing subject number:  6\n",
      "processing subject number:  7\n",
      "processing subject number:  8\n",
      "processing subject number:  9\n",
      "processing subject number:  10\n",
      "processing subject number:  11\n",
      "processing subject number:  12\n",
      "processing subject number:  13\n",
      "processing subject number:  14\n",
      "processing subject number:  15\n",
      "processing subject number:  16\n",
      "processing subject number:  17\n",
      "processing subject number:  18\n",
      "processing subject number:  19\n",
      "processing subject number:  20\n",
      "processing subject number:  21\n",
      "processing subject number:  22\n",
      "processing subject number:  23\n",
      "processing subject number:  24\n",
      "processing subject number:  25\n",
      "processing subject number:  26\n",
      "processing subject number:  27\n",
      "processing subject number:  28\n",
      "processing subject number:  29\n",
      "processing subject number:  30\n",
      "processing subject number:  31\n",
      "processing subject number:  32\n",
      "processing subject number:  33\n",
      "processing subject number:  34\n",
      "processing subject number:  35\n",
      "processing subject number:  36\n",
      "processing subject number:  37\n",
      "processing subject number:  38\n",
      "processing subject number:  39\n",
      "processing subject number:  40\n",
      "processing subject number:  41\n",
      "processing subject number:  42\n",
      "processing subject number:  43\n",
      "processing subject number:  44\n",
      "processing subject number:  45\n",
      "processing subject number:  46\n",
      "processing subject number:  47\n",
      "processing subject number:  48\n",
      "processing subject number:  49\n",
      "processing subject number:  50\n",
      "processing subject number:  51\n",
      "processing subject number:  52\n",
      "processing subject number:  53\n",
      "processing subject number:  54\n",
      "processing subject number:  55\n",
      "processing subject number:  56\n",
      "processing subject number:  57\n",
      "processing subject number:  58\n",
      "processing subject number:  59\n",
      "processing subject number:  60\n",
      "processing subject number:  61\n",
      "processing subject number:  62\n",
      "processing subject number:  63\n",
      "processing subject number:  64\n",
      "processing subject number:  65\n",
      "processing subject number:  66\n",
      "processing subject number:  67\n",
      "processing subject number:  68\n",
      "processing subject number:  69\n",
      "processing subject number:  70\n",
      "processing subject number:  71\n",
      "processing subject number:  72\n",
      "processing subject number:  73\n",
      "processing subject number:  74\n",
      "processing subject number:  75\n",
      "processing subject number:  76\n",
      "processing subject number:  77\n",
      "processing subject number:  78\n",
      "processing subject number:  79\n",
      "processing subject number:  80\n",
      "processing subject number:  81\n",
      "processing subject number:  82\n",
      "processing subject number:  83\n",
      "processing subject number:  84\n",
      "processing subject number:  85\n",
      "processing subject number:  86\n",
      "processing subject number:  87\n",
      "processing subject number:  88\n",
      "Sampling frequency of the instance is already 128.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 128.0, returning unmodified.\n",
      "processing subject number:  89\n",
      "processing subject number:  90\n",
      "processing subject number:  91\n",
      "processing subject number:  92\n",
      "Sampling frequency of the instance is already 128.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 128.0, returning unmodified.\n",
      "processing subject number:  93\n",
      "processing subject number:  94\n",
      "processing subject number:  95\n",
      "processing subject number:  96\n",
      "processing subject number:  97\n",
      "processing subject number:  98\n",
      "processing subject number:  99\n",
      "processing subject number:  100\n",
      "Sampling frequency of the instance is already 128.0, returning unmodified.\n",
      "Sampling frequency of the instance is already 128.0, returning unmodified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:65: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_RorL1 = mne.io.read_raw_edf(\"D:\\physionet_dataset\\S\" + str(subject) +\"\\S\" + str(subject) +\"R04.edf\",preload = True, verbose=False)\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:66: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_RorL2 = mne.io.read_raw_edf(\"D:\\physionet_dataset\\S\" + str(subject) +\"\\S\" + str(subject) +\"R08.edf\",preload = True, verbose=False)\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:67: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_RorL3 = mne.io.read_raw_edf(\"D:\\physionet_dataset\\S\" + str(subject) +\"\\S\" + str(subject) +\"R12.edf\",preload = True, verbose=False)\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:78: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_Both1 = mne.io.read_raw_edf(\"D:\\physionet_dataset\\S\" + str(subject) +\"\\S\" + str(subject) +\"R06.edf\",preload = True, verbose=False)\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:79: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_Both2 = mne.io.read_raw_edf(\"D:\\physionet_dataset\\S\" + str(subject) +\"\\S\" + str(subject) +\"R10.edf\",preload = True, verbose=False)\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:80: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw_Both3 = mne.io.read_raw_edf(\"D:\\physionet_dataset\\S\" + str(subject) +\"\\S\" + str(subject) +\"R14.edf\",preload = True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing subject number:  101\n",
      "processing subject number:  102\n",
      "processing subject number:  103\n",
      "processing subject number:  104\n",
      "processing subject number:  105\n",
      "processing subject number:  106\n",
      "processing subject number:  107\n",
      "processing subject number:  108\n",
      "processing subject number:  109\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "148 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "148 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "P059 -318.4516872532656 15\n",
      "P059 1038.9442350925492 15\n",
      "P059 -1074.055918632143 16\n",
      "P059 299.1623359364581 16\n",
      "P059 -1196.6689362296906 20\n",
      "P059 274.9148497256546 20\n",
      "P059 -1147.5470456986693 70\n",
      "P059 178.30133611108454 70\n",
      "P059 -1104.3980624949231 97\n",
      "P059 81.10133720571451 97\n",
      "P059 -1091.8251635226216 131\n",
      "P059 20.68441134035783 131\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "147 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "148 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "147 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "P084 -1019.3821703246222 141\n",
      "P084 774.6617274743861 141\n",
      "P084 -1070.1889576620583 142\n",
      "P084 1020.7164674663519 142\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "188 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "187 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P095 -142.26261475457747 118\n",
      "P095 1047.8370281991654 118\n",
      "P095 -148.75865329411093 119\n",
      "P095 1006.5569166385028 119\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "153 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "148 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "147 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "150 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "152 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n",
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:138: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combine_epoch = mne.concatenate_epochs([RorL_epochs, Both_epochs])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git\\BCI_MI_Study\\OtherData_utilize.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  train_data = EEG_epoch[key_subs]['Raw_Epoch'].copy().get_data() * 10e5\n"
     ]
    }
   ],
   "source": [
    "RAW_data_RorL, RAW_data_Both = Class_Physio.GetRaw(num_subject= num_subject_physionet)\n",
    "EEG_physio_Epochs = Class_Physio.Get_epoch(RAW_data_RorL, RAW_data_Both, tmin=-2.0, tmax=4.0, crop=(0,4),baseline = (-0.5,0.0),band_pass= (6,32),trial_removal_th = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dictionaries into a single dictionary\n",
    "combined_epochs = {**Unicorn_Epochs, **EEG_compet_Epochs, **EEG_physio_Epochs}\n",
    "calibrate_size = calibrate_size / combined_epochs[target_data_0]['Raw_Epoch'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear Memory\n",
    "del Unicorn_Epochs\n",
    "del EEG_compet_Epochs\n",
    "del EEG_physio_Epochs\n",
    "del RAW_data_RorL\n",
    "del RAW_data_Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllBCIClass.ComputeEA(combined_epochs, target_subject= target_data_0, calibrate_size=calibrate_size)\n",
    "if calibrate_size != 0:\n",
    "    target_data = target_data_0 + \"_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "CSP2D_Epoch = AllBCIClass.computeCSPFeatures(combined_epochs, target_subject = target_data , target_subject_0= target_data_0) #For wLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train wLTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't make the python class yet because I need to check the correction of this purpose later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Custom loss function\n",
    "class CustomLossLL1(tf.keras.losses.Loss):\n",
    "    def __init__(self, lambda_t, model):\n",
    "        super().__init__()\n",
    "        self.lambda_t = lambda_t\n",
    "        self.cross_entropy = CategoricalCrossentropy()\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        ce_loss = self.cross_entropy(y_true, y_pred)\n",
    "        ws = self.get_weights_from_model()\n",
    "        reg_term = self.regularization_term(ws)\n",
    "        return ce_loss + self.lambda_t * reg_term\n",
    "\n",
    "    def get_weights_from_model(self):\n",
    "        model_weights = []\n",
    "        for layer in self.model.layers:\n",
    "            if len(layer.get_weights()) > 0:\n",
    "                model_weights.append(layer.get_weights()[0])\n",
    "        # return tf.concat([tf.reshape(w, [-1]) for w in model_weights], axis=0)\n",
    "        return model_weights[0]\n",
    "\n",
    "    def regularization_term(self, ws):\n",
    "        reg_term = tf.pow(tf.norm(ws, ord='euclidean'),2)\n",
    "        return reg_term\n",
    "\n",
    "\n",
    "# Custom training loop\n",
    "def custom_train_step(model, optimizer, x, y, custom_loss):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True) # Perform a forward pass and compute the predictions\n",
    "        loss = custom_loss(y, y_pred) # Compute the custom loss\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_weight_LL(X_train, y_train, lambd, num_tier=10, learning_rate = 0.01):\n",
    "    n_classes = np.unique(y_train).size\n",
    "    _, sequential_indices = np.unique(y_train, return_inverse=True)\n",
    "    y_one_hot = tf.keras.utils.to_categorical(sequential_indices, num_classes=n_classes)\n",
    "\n",
    "    lambda_t = lambd  # Regularization parameter\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(n_classes, input_shape=(X_train.shape[1],), activation='softmax')  # Adjust input_shape to match the number of features in X\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate)\n",
    "    custom_loss = CustomLossLL1(lambda_t, model)\n",
    "\n",
    "    # Custom training loop\n",
    "    epochs = num_tier\n",
    "    lowest_loss = float('inf')\n",
    "    best_weights = None\n",
    "    for epoch in range(epochs):\n",
    "        loss = custom_train_step(model, optimizer, X_train, y_one_hot, custom_loss)\n",
    "        loss_value = loss.numpy()\n",
    "        if loss_value < lowest_loss:\n",
    "            lowest_loss = loss_value\n",
    "            best_weights = [layer.get_weights() for layer in model.layers]\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")\n",
    "\n",
    "    return best_weights[0], lowest_loss\n",
    "\n",
    "def build_clf_params(data, target_subjects ,condition, load_weight):\n",
    "\n",
    "    for sub in data.keys():\n",
    "        if (sub  != target_subjects) and  (sub != target_data_0): #Don't apply weight to target subject\n",
    "            # Where the tranining data is stored\n",
    "            if condition == \"noEA\":\n",
    "                X = data[sub]['Raw_csp']\n",
    "                y = data[sub]['Raw_csp_label']\n",
    "                store_ws = 'ws_Raw'\n",
    "                with open(noEA_wLTL_weight, 'rb') as file:\n",
    "                    loaded_weight = pickle.load(file)\n",
    "\n",
    "            else:\n",
    "                X = data[sub]['EA_csp']\n",
    "                y = data[sub]['EA_csp_label']\n",
    "                store_ws = 'ws_EA'\n",
    "                with open(EA_wLTL_weight, 'rb') as file:\n",
    "                    loaded_weight = pickle.load(file)\n",
    "\n",
    "            if load_weight == False:\n",
    "                weights, loss = train_weight_LL(X_train=X, y_train=y, lambd= 0.1, num_tier=500, learning_rate= 0.01)\n",
    "                print(\"weights of \", str(sub), \": \", weights)\n",
    "                print(\"Lowest loss of \", str(sub), \": \", loss)\n",
    "                data[sub][store_ws] = weights\n",
    "\n",
    "            else:\n",
    "                for sub in data.keys():\n",
    "                    if (sub  != target_subjects) and  (sub != target_data_0): #Don't apply weight to target subject\n",
    "                        data[sub][store_ws] = loaded_weight[sub][store_ws][0]\n",
    "\n",
    "build_clf_params(CSP2D_Epoch, target_subjects= target_data ,condition = condition_wLTL, load_weight = load_wLTL_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:184: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "c:\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\pipo_\\AppData\\Local\\Temp\\ipykernel_7328\\1432473110.py:12: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sigma_P = np.cov(P, rowvar=False)\n",
      "c:\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2705: RuntimeWarning: divide by zero encountered in divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "c:\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2705: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n",
      "C:\\Users\\pipo_\\AppData\\Local\\Temp\\ipykernel_7328\\1432473110.py:13: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  sigma_Q = np.cov(Q, rowvar=False)\n",
      "c:\\Python311\\Lib\\site-packages\\numpy\\linalg\\linalg.py:2139: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    }
   ],
   "source": [
    "# First define the kl divergence\n",
    "def KL_div(P, Q):\n",
    "    # First convert to np array\n",
    "    P = np.array(P)\n",
    "    Q = np.array(Q)\n",
    "    \n",
    "    # Then compute their means, datain shape of samples x feat\n",
    "    mu_P = np.mean(P, axis=0)\n",
    "    mu_Q = np.mean(Q, axis=0)    \n",
    "\n",
    "    # Compute their covariance\n",
    "    sigma_P = np.cov(P, rowvar=False)\n",
    "    sigma_Q = np.cov(Q, rowvar=False)  \n",
    "\n",
    "    diff = mu_Q - mu_P\n",
    "\n",
    "    inv_sigma_Q = np.linalg.inv(sigma_Q)\n",
    "    term1 = np.dot(np.dot(diff.T, inv_sigma_Q), diff)\n",
    "    \n",
    "    # Calculate the trace term trace(Sigma_Q^{-1} * Sigma_P)\n",
    "    term2 = np.trace(np.dot(inv_sigma_Q, sigma_P))\n",
    "    \n",
    "    # Calculate the determinant term ln(det(Sigma_P) / det(Sigma_Q))\n",
    "    det_sigma0 = np.linalg.det(sigma_P)\n",
    "    det_sigma1 = np.linalg.det(sigma_Q)\n",
    "\n",
    "    \n",
    "    epsilon = 1e-5\n",
    "    term3 = np.log((det_sigma0+epsilon) / (det_sigma1+epsilon))\n",
    "    \n",
    "    # Dimensionality of the data\n",
    "    K = mu_P.shape[0]\n",
    "    \n",
    "    # KL divergence\n",
    "    kl_div = 0.5 * (term1 + term2 - term3 - K)\n",
    "    \n",
    "    return kl_div\n",
    "\n",
    "# Compute kl divergence of target subject to each source subject\n",
    "def compute_all_kl_div(data, target_subjects , condition):\n",
    "    '''\n",
    "    Parameter:\n",
    "    data, is the whole data containing target and source data\n",
    "    '''\n",
    "    kl_div_score = []\n",
    "\n",
    "    if condition == \"noEA\":\n",
    "        target_data = 'Raw_csp'\n",
    "        label_name = 'Raw_csp_label'\n",
    "\n",
    "    else:\n",
    "        target_data = 'EA_csp'\n",
    "        label_name = 'EA_csp_label'\n",
    "        \n",
    "    # cal P from target data\n",
    "    label_tgt =  data[target_subjects][label_name]\n",
    "    P_left =  data[target_subjects][target_data][np.where(label_tgt == 0)]\n",
    "    P_right = data[target_subjects][target_data][np.where(label_tgt == 1)]\n",
    "    P_non = data[target_subjects][target_data][np.where(label_tgt == 2)]\n",
    "    P_feet = data[target_subjects][target_data][np.where(label_tgt == 3)]\n",
    "\n",
    "    tgt_data = target_subjects + \"_test\"\n",
    "\n",
    "    #cal Q from each source subject\n",
    "    for sub in data.keys():\n",
    "        if (sub != target_subjects) and (sub != tgt_data):\n",
    "            label_src =  data[sub][label_name]\n",
    "            Q_left =  data[sub][target_data][np.where(label_src == 0)]\n",
    "            Q_right = data[sub][target_data][np.where(label_src == 1)]\n",
    "            Q_non = data[sub][target_data][np.where(label_src == 2)]\n",
    "            Q_feet = data[sub][target_data][np.where(label_src == 3)]\n",
    "\n",
    "            kl_left = KL_div(P_left, Q_left)\n",
    "            kl_right = KL_div(P_right, Q_right)\n",
    "            kl_non = KL_div(P_non, Q_non)\n",
    "            kl_feet = KL_div(P_feet, Q_feet)\n",
    "\n",
    "            kl_div_temp = [kl_left, kl_right, kl_non, kl_feet]\n",
    "\n",
    "            kl_div_score.append(kl_div_temp)\n",
    "\n",
    "    data[target_subjects]['kl_div'] = kl_div_score\n",
    "\n",
    "\n",
    "compute_all_kl_div(CSP2D_Epoch, target_subjects=target_data_0 ,condition = condition_wLTL) #target_sub for cal KL is calibrate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06618413809800285, 0.04573975811500275, 0.11406098197139296, 0.023728044896911663, 0.3782982386580213, 11685.790689317333, 0.0391647404095455, 0.018382126684997696, 78119.95523770309, 0.000209348420493363, 0.0028622153871998256, 0.016547952785313822, 0.0005250849551107873, 0.020098158746728774, 0.00013571150993708743, 0.015919092937159103, 0.0005883298729860495, 0.011469607628102925, 0.008812562774410155, 0.001213886221913668, 0.009663935082353612, 0.029821050964578898, 0.03979814333247943, 0.000374301511648631, 0.00021743263610765552, 0.8698519420021239, 0.0009334743456549663, 0.00041287063270507374, 0.0006172242329218408, 0.007327561120042861, 0.0013124763553857988, 0.06422820188958975, 0.5443141281902858, 0.0013218655465571994, 0.0032216115290923967, 0.000961417641141386, 0.014064010771518297, 0.0036925806250290563, 0.007532309000194309, 0.10176115708773661, 0.025522656699640076, 0.0018758025670813038, 0.001371477919809188, 4.088986628610315, 0.00048490778815511287, 3.722550838698915e-05, 0.0002904365255323959, 0.005429843087659384, 0.0010343574242864665, 0.0019381618069102176, 0.0050852979112612235, 0.001197896902879527, 43.52296426952574, 0.06121549718703923, 0.0026154120539788983, 0.033061733428630495, 55555.27645143792, 0.0010743693782331288, 0.0007633237515269867, 0.0003559228189625804, 999608626202.0325, 0.0009771956343415892, 0.0008685014060783067, 0.02788907481249158, 0.10830003341115554, 0.010471646428919314, 0.00011653975199146369, 0.0014966005199267384, 0.015545469267213738, 0.36739822536511896, 0.0010811977481373018, 0.00024785312674484663, 0.0004069080720456915, 0.044921353300506846, 0.04727557905766002, 0.00778145837749261, 0.0001654430782109505, 0.011914601897933533, 0.003304102619085097, 0.0027998402171105995, 0.00013987950468742638, 0.005739214773945688, 0.001874275815717139, 13.359328323903645, 0.0014854956204125838, 0.026725330865385973, 0.3417203338996463, 0.0035960948497706477, 0.00019787385114495353, 0.00026930200165804926, 0.053899132997589014, 0.011582335321887478, 0.32849733743688386, 0.005451201974144313, 0.8389746500339917, 1.7384838079087974, 0.007861140022030413, 0.0036332713228326716, 0.004719078203701414, 0.0011523176734132673, 0.005327018781872359, 0.0019824627872680766, 0.07796236352038985, 0.0011941027985144436, 0.005933857039166401, 0.025402557120868727, 2589.6442643293317, 0.005443704152559109, 0.0019347389290399546, 0.0005587322005062414, 0.0005416424528171471, 0.09861643052241564, 0.004600347633899387, 0.020986368395449644, 0.2589953654739977, 9.415373160270558, 0.13891789630737475, 0.0006920563961141962]\n",
      "[0.0031521468955537438, 0.1705929564302314, 0.142029307156371, 6.316387959755729, 23.869148939628634, 1085.7059577497148, 0.05535397067895364, 19.281849228245694, 7032.112826630314, 0.001550168835865347, 0.0025955359833010777, 4.774977035985293, 0.002486979514338319, 0.03811204562247473, 0.021743403202907467, 0.00032600829534389, 0.00103348052440442, 0.0013855111282891496, 0.011180415576324479, 0.0006427134659282846, 0.019363127340603796, 0.0027560338769785178, 0.11682278639335343, 0.00521199453758218, 0.011721762666897447, 1.5314132669980094, 0.003464985362782587, 6.475182452161059e-05, 0.0020128512896022484, 0.00608270079498582, 4.133204094995328e-05, 13.67744019301232, 0.027872829374438936, 0.001040608928573272, 0.11771086662837787, 0.4477825186717661, 0.2818249520621727, 51793.42169757691, 0.2376703591538944, 0.46758824936512616, 0.04687534680064264, 0.018162381622923825, 0.003778244956108651, 1.0745213614700195, 0.002649776427303353, 0.0011190515132675242, 0.02844923475991761, 0.0007087113362057376, 0.0038124629375374678, 0.0032924469181155104, 2.101265269718478, 0.0009856499373873217, 104.91837489909099, 0.026389061017867293, 0.0002954667066704529, 0.011508905581490434, 58.70946136572131, 0.040940373899676724, 7.337538441708521e-05, 0.002999194178541216, 0.0023791063366941493, 0.00017192420504362867, 385.400586749218, 0.030562171198153278, 0.044832255515443856, 0.0032380685818534445, 0.006216676837763705, 0.0362205339680959, 0.024109198489993093, 0.013584833155399307, 0.001392465381262361, 11.413752279793735, 0.003633844570283976, 0.011759673828378862, 23069.740671122963, 0.016653168285486797, 0.0017132158753080744, 0.0015971052538158491, 0.020093584779835406, 0.00210747725143639, 0.0005184671948581374, 0.003788779956125997, 2.6873515736545173, 0.9590515226396663, 0.562462083436654, 0.03076609315131709, 1.3663239350189984, 0.07678992872232365, 0.00020566196165633588, 8.616022229482772e-05, 0.05328671319969168, 0.0599487070746859, 7.599103586786404, 0.003454298600658494, 1.961895759433449e-05, 0.053671730752053004, 0.002508470863913715, 0.00030309838703669557, 0.031555900420208206, 0.029440698963411623, 0.37524299732828187, 0.015087286630686349, 0.010110816178242932, 0.010307388143427885, 0.002656714745847036, 0.007377321356596063, 119.23600274426703, 0.015041097164129852, 3.8850438962562217, 0.0010311626924626, 0.0054026670659748375, 12.22644431403176, 0.0014714790695862256, 113.72430603988076, 0.010395878353910712, 0.10365437773621396, 731310.409049054, 0.014534009172178118]\n",
      "[[6.62100412e-14 3.86676232e-09 6.38367912e-10]\n",
      " [4.57576597e-14 2.09267664e-07 1.22641033e-09]\n",
      " [1.14105623e-13 1.74228420e-07 7.31567332e-02]\n",
      " [2.37373316e-14 7.74836065e-06 2.88930042e-07]\n",
      " [3.78446297e-13 2.92804647e-05 1.75992248e-04]\n",
      " [1.16903643e-08 1.33184367e-03 5.84935320e-07]\n",
      " [3.91800687e-14 6.79031324e-08 2.44880733e-09]\n",
      " [1.83893211e-14 2.36531896e-05 6.54131973e-06]\n",
      " [7.81505297e-08 8.62634573e-03 3.28536256e-08]\n",
      " [2.09430355e-16 1.90160378e-09 4.55735358e-11]\n",
      " [2.86333560e-15 3.18396353e-09 2.83622124e-09]\n",
      " [1.65544293e-14 5.85750027e-06 1.27476804e-03]\n",
      " [5.25290462e-16 3.05079649e-09 4.41631701e-11]\n",
      " [2.01060247e-14 4.67523332e-08 1.04588440e-08]\n",
      " [1.35764625e-16 2.66727964e-08 2.60732663e-09]\n",
      " [1.59253233e-14 3.99916830e-10 7.01329698e-09]\n",
      " [5.88560133e-16 1.26777834e-09 1.46878174e-08]\n",
      " [1.14740966e-14 1.69961693e-09 3.03874408e-10]\n",
      " [8.81601183e-15 1.37150999e-08 1.82703350e-09]\n",
      " [1.21436131e-15 7.88421446e-10 5.15759298e-11]\n",
      " [9.66771734e-15 2.37528940e-08 3.88286684e-10]\n",
      " [2.98327223e-14 3.38084750e-09 6.52914379e-10]\n",
      " [3.98137195e-14 1.43307391e-07 2.11084983e-09]\n",
      " [3.74448005e-16 6.39359293e-09 6.58762109e-11]\n",
      " [2.17517735e-16 1.43791745e-08 3.02730722e-07]\n",
      " [8.70192384e-13 1.87859618e-06 2.26829881e-10]\n",
      " [9.33839688e-16 4.25052362e-09 1.58658242e-10]\n",
      " [4.13032222e-16 7.94315505e-11 1.71977068e-10]\n",
      " [6.17465801e-16 2.46917983e-09 4.85734402e-10]\n",
      " [7.33042897e-15 7.46169485e-09 8.64778522e-09]\n",
      " [1.31299003e-15 5.07023257e-11 2.18515538e-10]\n",
      " [6.42533395e-14 1.67782188e-05 1.89712200e-09]\n",
      " [5.44527161e-13 3.41918096e-08 2.39427625e-10]\n",
      " [1.32238290e-15 1.27652280e-09 3.51623016e-11]\n",
      " [3.22287240e-15 1.44396806e-07 6.54171959e-09]\n",
      " [9.61793920e-16 5.49298186e-07 3.11847088e-03]\n",
      " [1.40695151e-14 3.45716790e-07 2.30024322e-08]\n",
      " [3.69402582e-15 6.35353802e-02 4.12208171e-09]\n",
      " [7.53525699e-15 2.91552018e-07 2.91879170e-10]\n",
      " [1.01800984e-13 5.73594025e-07 6.25526730e-08]\n",
      " [2.55326457e-14 5.75023407e-08 1.55545842e-08]\n",
      " [1.87653672e-15 2.22799302e-08 1.28776393e-08]\n",
      " [1.37201469e-15 4.63480152e-09 4.82513947e-06]\n",
      " [4.09058697e-12 1.31812344e-06 1.15198287e-08]\n",
      " [4.85097571e-16 3.25050069e-09 2.04323621e-10]\n",
      " [3.72400777e-17 1.37274891e-09 7.56695712e-10]\n",
      " [2.90550196e-16 3.48988904e-08 1.31644967e-10]\n",
      " [5.43196821e-15 8.69381530e-10 1.35827372e-03]\n",
      " [1.03476225e-15 4.67677698e-09 4.48293653e-11]\n",
      " [1.93892036e-15 4.03886941e-09 8.08705808e-11]\n",
      " [5.08728819e-15 2.57763792e-06 2.61926678e-10]\n",
      " [1.19836573e-15 1.20910420e-09 8.37999100e-11]\n",
      " [4.35399982e-11 1.28704160e-04 2.62247892e-06]\n",
      " [6.12394556e-14 3.23716598e-08 6.67359782e-10]\n",
      " [2.61643567e-15 3.62451233e-10 2.34984578e-11]\n",
      " [3.30746731e-14 1.41180611e-08 2.12119697e-10]\n",
      " [5.55770196e-08 7.20193381e-05 2.07762909e-08]\n",
      " [1.07478986e-15 5.02218648e-08 7.45570952e-10]\n",
      " [7.63622500e-16 9.00101363e-11 2.57781796e-11]\n",
      " [3.56062120e-16 3.67913407e-09 6.37406216e-11]\n",
      " [9.99999852e-01 2.91846765e-09 1.47000490e-03]\n",
      " [9.77578088e-16 2.10900716e-10 8.06282768e-09]\n",
      " [8.68841319e-16 4.72773800e-04 8.82474433e-01]\n",
      " [2.78999900e-14 3.74908454e-08 3.39592252e-09]\n",
      " [1.08342420e-13 5.49960653e-08 3.86406958e-08]\n",
      " [1.04757448e-14 3.97216310e-09 7.91545656e-08]\n",
      " [1.16585363e-16 7.62604427e-09 1.16700148e-10]\n",
      " [1.49718626e-15 4.44320016e-08 4.46650480e-09]\n",
      " [1.55515534e-14 2.95749352e-08 1.90070252e-08]\n",
      " [3.67542017e-13 1.66646171e-08 1.51541443e-10]\n",
      " [1.08162091e-15 1.70814776e-09 9.14845572e-09]\n",
      " [2.47950131e-16 1.40013358e-05 5.58329812e-11]\n",
      " [4.07067327e-16 4.45766448e-09 3.81531423e-10]\n",
      " [4.49389346e-14 1.44256804e-08 3.33836904e-09]\n",
      " [4.72940817e-14 2.82998245e-02 3.02564200e-07]\n",
      " [7.78450388e-15 2.04285669e-08 1.96836280e-11]\n",
      " [1.65507829e-16 2.10161481e-09 4.52398064e-09]\n",
      " [1.19192650e-14 1.95918104e-09 3.15712155e-10]\n",
      " [3.30539578e-15 2.46489517e-08 4.43137154e-10]\n",
      " [2.80093602e-15 2.58525821e-09 1.23777980e-09]\n",
      " [1.39934251e-16 6.36007610e-10 1.11389318e-10]\n",
      " [5.74146098e-15 4.64772489e-09 1.70130205e-11]\n",
      " [1.87500937e-15 3.29659440e-06 3.65071022e-02]\n",
      " [1.33645569e-11 1.17647572e-06 5.87892474e-08]\n",
      " [1.48607701e-15 6.89976471e-07 3.85120467e-09]\n",
      " [2.67357906e-14 3.77409980e-08 7.10171946e-10]\n",
      " [3.41854076e-13 1.67607985e-06 1.17151863e-06]\n",
      " [3.59750229e-15 9.41987835e-08 2.30695272e-10]\n",
      " [1.97951295e-16 2.52287076e-10 6.89709022e-12]\n",
      " [2.69407401e-16 1.05693393e-10 8.07971433e-12]\n",
      " [5.39202280e-14 6.53672121e-08 8.03600036e-08]\n",
      " [1.15868684e-14 7.35395302e-08 1.93510109e-09]\n",
      " [3.28625904e-13 9.32187756e-06 3.46807047e-04]\n",
      " [5.45333546e-15 4.23741409e-09 5.19096229e-09]\n",
      " [8.39303007e-13 2.40667229e-11 9.09426023e-13]\n",
      " [1.73916421e-12 6.58395161e-08 1.38751505e-07]\n",
      " [7.86421671e-15 3.07716009e-09 3.10411902e-09]\n",
      " [3.63469331e-15 3.71813073e-10 1.80547201e-10]\n",
      " [4.72092515e-15 3.87098605e-08 2.51618425e-10]\n",
      " [1.15276867e-15 3.61151270e-08 1.31952876e-10]\n",
      " [5.32910366e-15 4.60313409e-07 9.75701387e-05]\n",
      " [1.98323868e-15 1.85076881e-08 2.60905457e-08]\n",
      " [7.79928763e-14 1.24030143e-08 8.73462360e-08]\n",
      " [1.19457015e-15 1.26441506e-08 1.49951205e-10]\n",
      " [5.93617943e-15 3.25901197e-09 5.65870211e-10]\n",
      " [2.54124991e-14 9.04981563e-09 1.51021197e-10]\n",
      " [2.59065780e-09 1.46267702e-04 4.48785140e-07]\n",
      " [5.44583470e-15 1.84510271e-08 5.53546421e-09]\n",
      " [1.93549615e-15 4.76581259e-06 1.09975324e-08]\n",
      " [5.58950876e-16 1.26493504e-09 2.54797529e-11]\n",
      " [5.41854440e-16 6.62749235e-09 7.32116248e-12]\n",
      " [9.86550269e-14 1.49982713e-05 2.40483089e-07]\n",
      " [4.60214811e-15 1.80507445e-09 1.11922021e-09]\n",
      " [2.09945820e-14 1.39506462e-04 4.46406037e-07]\n",
      " [2.59096731e-13 1.27527022e-08 8.63581541e-08]\n",
      " [9.41905814e-12 1.27153605e-07 1.05839960e-06]\n",
      " [1.38972266e-13 8.97103983e-01 7.29718357e-08]\n",
      " [6.92327252e-16 1.78289784e-08 2.24270756e-10]]\n"
     ]
    }
   ],
   "source": [
    "def compute_similarity_weights(data, target_subjects):\n",
    "    kl = data[target_subjects]['kl_div']\n",
    "    KL_inv_left = []\n",
    "    KL_inv_right = []\n",
    "    KL_inv_non = []\n",
    "    KL_inv_feet = []\n",
    "\n",
    "    alpha_s = []\n",
    "    eps = 0.0001\n",
    "    \n",
    "    #equation (9)\n",
    "    for val in kl:\n",
    "        if val != 0: \n",
    "            KL_inv_left.append(1/((val[0] + eps)**4))\n",
    "            KL_inv_right.append(1/((val[1] + eps)**4))\n",
    "            KL_inv_non.append(1/((val[2] + eps)**4))\n",
    "            KL_inv_feet.append(1/((val[3] + eps)**4))\n",
    "\n",
    "    print(KL_inv_left)\n",
    "    print(KL_inv_right)\n",
    "    \n",
    "    for i in range(0,len(KL_inv_left)):\n",
    "        temp = [KL_inv_left[i]/sum(KL_inv_left), KL_inv_right[i]/sum(KL_inv_right), KL_inv_non[i]/sum(KL_inv_non), KL_inv_feet[i]/sum(KL_inv_feet)]\n",
    "        alpha_s.append(temp)\n",
    "\n",
    "    alpha_s = np.array(alpha_s)\n",
    "    print(np.array(alpha_s[:, ~np.isnan(alpha_s).any(axis=0)]))\n",
    "    data[target_subjects]['alpha_s'] = alpha_s[:, ~np.isnan(alpha_s).any(axis=0)]\n",
    "\n",
    "compute_similarity_weights(CSP2D_Epoch, target_subjects=target_data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02727691 -0.42583612  0.33261362]\n",
      " [ 0.29017637 -0.5050107  -1.10895482]\n",
      " [-0.26716578  0.6209165  -0.05062655]\n",
      " [-0.07626894  0.04688939  0.13303302]\n",
      " [ 0.29150302  0.18659458  0.40716793]]\n",
      "[[ 34.2684298  -18.90194439 -32.04070633   3.07500699   5.61352328]\n",
      " [-18.90194439 183.46030421 -39.17880668 -22.54088022 -53.94418502]\n",
      " [-32.04070633 -39.17880668  53.71447784   4.98409952   2.03071052]\n",
      " [  3.07500699 -22.54088022   4.98409952   3.00247287   4.73327775]\n",
      " [  5.61352328 -53.94418502   2.03071052   4.73327775  33.42014593]]\n"
     ]
    }
   ],
   "source": [
    "def compute_ETL_and_mu_ws(data, target_subjects, condition):\n",
    "\n",
    "    mu_ws = 0\n",
    "    temp_ws = 0\n",
    "\n",
    "    if condition == \"noEA\":\n",
    "        ws_name = 'ws_Raw'\n",
    "    else:\n",
    "        ws_name = 'ws_EA'\n",
    "\n",
    "    alpha_s = np.array(data[target_subjects]['alpha_s'])\n",
    "\n",
    "    tgt_data = target_subjects + \"_test\"\n",
    "    index_count = 0\n",
    "\n",
    "    for sub in data.keys():\n",
    "        if (sub != target_subjects) and (sub != tgt_data):\n",
    "            ws = data[sub][ws_name][0]\n",
    "            mu_ws += ws * alpha_s[index_count]\n",
    "            index_count += 1\n",
    "\n",
    "    print(np.array(mu_ws))\n",
    "\n",
    "    index_count = 0\n",
    "    for sub in data.keys():\n",
    "        if (sub != target_subjects) and (sub != tgt_data):\n",
    "            ws = data[sub][ws_name][0]\n",
    "            ws_min_mu = np.dot(((ws * alpha_s[index_count]) - mu_ws), np.transpose((ws * alpha_s[index_count]) - mu_ws))\n",
    "            temp_ws += ws_min_mu #equation (11)\n",
    "            index_count += 1\n",
    "\n",
    "    print(np.array(temp_ws))\n",
    "\n",
    "    den = temp_ws\n",
    "    nom = np.trace(temp_ws) #Return the sum along diagonals of the array.\n",
    "    Sigma_TL = den/nom\n",
    "\n",
    "    data[target_subjects]['Sigma_TL'] = Sigma_TL\n",
    "    data[target_subjects]['mu_ws'] = mu_ws\n",
    "\n",
    "compute_ETL_and_mu_ws(CSP2D_Epoch, target_subjects = target_data_0, condition=condition_wLTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(5, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(CSP2D_Epoch[target_data_0]['Sigma_TL']).shape)\n",
    "print(np.array(CSP2D_Epoch[target_data_0]['mu_ws']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: -1437.3013916015625\n",
      "Epoch 20, Loss: -1668.6702880859375\n",
      "Epoch 40, Loss: -1701.068359375\n",
      "Epoch 60, Loss: -1711.8956298828125\n",
      "Epoch 80, Loss: -1738.6224365234375\n",
      "Epoch 100, Loss: -1772.1365966796875\n",
      "Epoch 120, Loss: -1809.3277587890625\n",
      "Epoch 140, Loss: -1849.562255859375\n",
      "Epoch 160, Loss: -1892.9244384765625\n",
      "Epoch 180, Loss: -1939.585205078125\n",
      "Epoch 200, Loss: -1989.7850341796875\n",
      "Epoch 220, Loss: -2043.8055419921875\n",
      "Epoch 240, Loss: -2101.973388671875\n",
      "Epoch 260, Loss: -2164.65185546875\n",
      "Epoch 280, Loss: -2232.23388671875\n",
      "Epoch 300, Loss: -2305.121826171875\n",
      "Epoch 320, Loss: -2383.713134765625\n",
      "Epoch 340, Loss: -2468.394775390625\n",
      "Epoch 360, Loss: -2559.530517578125\n",
      "Epoch 380, Loss: -2657.45751953125\n",
      "Epoch 400, Loss: -2762.479248046875\n",
      "Epoch 420, Loss: -2874.85888671875\n",
      "Epoch 440, Loss: -2994.820556640625\n",
      "Epoch 460, Loss: -3122.544677734375\n",
      "Epoch 480, Loss: -3258.166259765625\n",
      "Epoch 500, Loss: -3401.77685546875\n",
      "Epoch 520, Loss: -3553.425537109375\n",
      "Epoch 540, Loss: -3713.1181640625\n",
      "Epoch 560, Loss: -3880.82080078125\n",
      "Epoch 580, Loss: -4056.45654296875\n",
      "Epoch 600, Loss: -4239.919921875\n",
      "Epoch 620, Loss: -4431.06494140625\n",
      "Epoch 640, Loss: -4629.720703125\n",
      "Epoch 660, Loss: -4835.6884765625\n",
      "Epoch 680, Loss: -5048.73876953125\n",
      "Epoch 700, Loss: -5268.63037109375\n",
      "Epoch 720, Loss: -5495.0908203125\n",
      "Epoch 740, Loss: -5727.84130859375\n",
      "Epoch 760, Loss: -5966.58544921875\n",
      "Epoch 780, Loss: -6211.02099609375\n",
      "Epoch 800, Loss: -6460.82861328125\n",
      "Epoch 820, Loss: -6715.68701171875\n",
      "Epoch 840, Loss: -6975.2685546875\n",
      "Epoch 860, Loss: -7239.2490234375\n",
      "Epoch 880, Loss: -7507.29638671875\n",
      "Epoch 900, Loss: -7779.08154296875\n",
      "Epoch 920, Loss: -8054.27490234375\n",
      "Epoch 940, Loss: -8332.5595703125\n",
      "Epoch 960, Loss: -8613.615234375\n",
      "Epoch 980, Loss: -8897.12109375\n",
      "Epoch 1000, Loss: -9182.7939453125\n",
      "Epoch 1020, Loss: -9470.3125\n",
      "Epoch 1040, Loss: -9759.384765625\n",
      "Epoch 1060, Loss: -10049.7431640625\n",
      "Epoch 1080, Loss: -10341.0986328125\n",
      "Epoch 1100, Loss: -10633.2060546875\n",
      "Epoch 1120, Loss: -10925.80078125\n",
      "Epoch 1140, Loss: -11218.64453125\n",
      "Epoch 1160, Loss: -11511.5048828125\n",
      "Epoch 1180, Loss: -11804.16015625\n",
      "Epoch 1200, Loss: -12096.3974609375\n",
      "Epoch 1220, Loss: -12388.0146484375\n",
      "Epoch 1240, Loss: -12678.822265625\n",
      "Epoch 1260, Loss: -12968.6416015625\n",
      "Epoch 1280, Loss: -13257.29296875\n",
      "Epoch 1300, Loss: -13544.62109375\n",
      "Epoch 1320, Loss: -13830.4755859375\n",
      "Epoch 1340, Loss: -14114.7275390625\n",
      "Epoch 1360, Loss: -14397.236328125\n",
      "Epoch 1380, Loss: -14677.875\n",
      "Epoch 1400, Loss: -14956.5458984375\n",
      "Epoch 1420, Loss: -15233.1376953125\n",
      "Epoch 1440, Loss: -15507.5625\n",
      "Epoch 1460, Loss: -15779.728515625\n",
      "Epoch 1480, Loss: -16049.5625\n",
      "Epoch 1500, Loss: -16316.9931640625\n",
      "Epoch 1520, Loss: -16581.962890625\n",
      "Epoch 1540, Loss: -16844.3984375\n",
      "Epoch 1560, Loss: -17104.2578125\n",
      "Epoch 1580, Loss: -17361.51171875\n",
      "Epoch 1600, Loss: -17616.11328125\n",
      "Epoch 1620, Loss: -17868.048828125\n",
      "Epoch 1640, Loss: -18117.26953125\n",
      "Epoch 1660, Loss: -18363.779296875\n",
      "Epoch 1680, Loss: -18607.544921875\n",
      "Epoch 1700, Loss: -18848.591796875\n",
      "Epoch 1720, Loss: -19086.88671875\n",
      "Epoch 1740, Loss: -19322.44921875\n",
      "Epoch 1760, Loss: -19555.271484375\n",
      "Epoch 1780, Loss: -19785.37890625\n",
      "Epoch 1800, Loss: -20012.759765625\n",
      "Epoch 1820, Loss: -20237.45703125\n",
      "Epoch 1840, Loss: -20459.478515625\n",
      "Epoch 1860, Loss: -20678.841796875\n",
      "Epoch 1880, Loss: -20895.587890625\n",
      "Epoch 1900, Loss: -21109.7421875\n",
      "Epoch 1920, Loss: -21321.33203125\n",
      "Epoch 1940, Loss: -21530.40234375\n",
      "Epoch 1960, Loss: -21736.978515625\n",
      "Epoch 1980, Loss: -21941.107421875\n",
      "weights of  Kawin :  [array([[ 0.77096146, -0.8411732 , -0.3447217 ],\n",
      "       [-0.12301793,  0.6997117 , -0.38025033],\n",
      "       [ 0.03885552,  0.13630371,  0.7179352 ],\n",
      "       [-0.7183641 , -0.81778085, -0.50701904],\n",
      "       [-0.31985554, -0.24386527, -0.00303791]], dtype=float32), array([ 0.00999978, -0.00999987,  0.00999981], dtype=float32)]\n",
      "loss of  Kawin :  1437.3014\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Classification TRAIN DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.70      0.64        10\n",
      "           1       0.70      0.70      0.70        10\n",
      "           2       0.50      0.40      0.44        10\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.59      0.60      0.59        30\n",
      "weighted avg       0.59      0.60      0.59        30\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[7 1 2]\n",
      " [1 7 2]\n",
      " [4 2 4]]\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Classification TEST DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.55      0.43        20\n",
      "           1       0.20      0.20      0.20        20\n",
      "           2       0.33      0.15      0.21        20\n",
      "\n",
      "    accuracy                           0.30        60\n",
      "   macro avg       0.30      0.30      0.28        60\n",
      "weighted avg       0.30      0.30      0.28        60\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[11  7  2]\n",
      " [12  4  4]\n",
      " [ 8  9  3]]\n"
     ]
    }
   ],
   "source": [
    "# Custom loss function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "class CustomLossLL2(tf.keras.losses.Loss):\n",
    "    \n",
    "    def __init__(self, lambda_t, model, mu, sigma_TL):\n",
    "        super().__init__()\n",
    "        self.lambda_t = lambda_t\n",
    "        self.cross_entropy = CategoricalCrossentropy()\n",
    "        self.model = model\n",
    "        self.mu = tf.convert_to_tensor(mu, dtype=tf.float32)\n",
    "        self.sigma_TL = tf.convert_to_tensor(sigma_TL, dtype=tf.float32)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        ce_loss = self.cross_entropy(y_true, y_pred)\n",
    "        wt = self.get_weights_from_model()\n",
    "        reg_term = self.regularization_term(wt)\n",
    "\n",
    "        return ce_loss + (self.lambda_t * tf.linalg.matmul(reg_term, wt))\n",
    "\n",
    "    def get_weights_from_model(self):\n",
    "        model_weights = []\n",
    "        for layer in self.model.layers:\n",
    "            if len(layer.get_weights()) > 0:\n",
    "                model_weights.append(layer.get_weights()[0])\n",
    "        return model_weights[0]\n",
    "\n",
    "    def regularization_term(self, wt):\n",
    "        diff = wt - self.mu\n",
    "        reg_term = 0.5 * tf.linalg.matmul(tf.linalg.matmul(tf.linalg.inv(self.sigma_TL), diff), tf.transpose(diff))\n",
    "        reg_term += 0.5 * tf.math.log(tf.linalg.det(self.sigma_TL))\n",
    "        return reg_term\n",
    "\n",
    "\n",
    "# Custom training loop\n",
    "def custom_train_step(model, optimizer, x, y, custom_loss):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True) # Perform a forward pass and compute the predictions\n",
    "        loss = custom_loss(y, y_pred) # Compute the custom loss\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train_weight_LL2(X_train, y_train, lambd, mu, sigma_TL, num_tier=10, learning_rate = 0.01):\n",
    "    n_classes = np.unique(y_train).size\n",
    "    _, sequential_indices = np.unique(y_train, return_inverse=True)\n",
    "    y_one_hot = tf.keras.utils.to_categorical(sequential_indices, num_classes=n_classes)\n",
    "\n",
    "    lambda_t = lambd  # Regularization parameter\n",
    "\n",
    "    model = Sequential([\n",
    "        Dense(n_classes, input_shape=(X_train.shape[1],), activation='softmax')  # Adjust input_shape to match the number of features in X\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate)\n",
    "    custom_loss = CustomLossLL2(lambda_t, model, mu, sigma_TL)\n",
    "\n",
    "    # Custom training loop\n",
    "    epochs = num_tier\n",
    "    lowest_loss = float('inf')\n",
    "    best_weights = None\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss = custom_train_step(model, optimizer, X_train, y_one_hot, custom_loss)\n",
    "        loss_value = loss.numpy()\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")\n",
    "\n",
    "        if (abs(loss_value) < lowest_loss):\n",
    "            lowest_loss = abs(loss_value)\n",
    "            best_model = model\n",
    "            best_weights = [layer.get_weights() for layer in model.layers]\n",
    "\n",
    "    return best_model, best_weights[0], lowest_loss\n",
    "\n",
    "def GetConfusionMatrix(model, X_train, X_test, y_train, y_test):\n",
    "    y_pred_prob = model.predict(X_train)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    _, y_train = np.unique(y_train, return_inverse=True)\n",
    "\n",
    "\n",
    "    print(\"Classification TRAIN DATA \\n=======================\")\n",
    "    print(classification_report(y_true= y_train, y_pred=y_pred))\n",
    "    print(\"Confusion matrix \\n=======================\")\n",
    "    print(confusion_matrix(y_true= y_train, y_pred=y_pred))\n",
    "\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    _, y_test = np.unique(y_test, return_inverse=True)\n",
    "    \n",
    "    print(\"Classification TEST DATA \\n=======================\")\n",
    "    print(classification_report(y_true=y_test, y_pred=y_pred))\n",
    "    print(\"Confusion matrix \\n=======================\")\n",
    "    print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "\n",
    "\n",
    "def tgt_test_wLTL(data, target_subjects ,condition):\n",
    "        tgt_data = target_subjects + \"_test\"\n",
    "\n",
    "        if condition == \"noEA\":\n",
    "            X = data[target_subjects]['Raw_csp']\n",
    "            y = data[target_subjects]['Raw_csp_label']\n",
    "            X_test = data[tgt_data]['Raw_csp']\n",
    "            y_test = data[tgt_data]['Raw_csp_label']\n",
    "            store_ws = 'wt_Raw'\n",
    "\n",
    "        else:\n",
    "            X = data[target_subjects]['EA_csp']\n",
    "            y = data[target_subjects]['EA_csp_label']\n",
    "            X_test = data[tgt_data]['EA_csp']\n",
    "            y_test = data[tgt_data]['EA_csp_label']\n",
    "            store_ws = 'wt_EA'\n",
    "\n",
    "        mu = data[target_subjects]['mu_ws']\n",
    "        sigma_TL = data[target_subjects]['Sigma_TL']\n",
    "\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "        \n",
    "        model, weights, loss = train_weight_LL2(X_train=X_train, y_train=y_train, mu =mu, sigma_TL=sigma_TL, lambd= 0.1, num_tier=2000, learning_rate= 0.01)\n",
    "        print(\"weights of \", str(target_subjects), \": \", weights)\n",
    "        print(\"loss of \", str(target_subjects), \": \", loss)\n",
    "        data[target_subjects][store_ws] = weights\n",
    "\n",
    "        GetConfusionMatrix(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "tgt_test_wLTL(CSP2D_Epoch, target_subjects= target_data_0 ,condition = condition_wLTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# noEA + LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Classification TRAIN DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.42      0.43      0.42      3113\n",
      "       Right       0.42      0.45      0.44      3072\n",
      "        Feet       0.41      0.36      0.38      3085\n",
      "\n",
      "    accuracy                           0.42      9270\n",
      "   macro avg       0.41      0.42      0.41      9270\n",
      "weighted avg       0.41      0.42      0.41      9270\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[1335  933  845]\n",
      " [ 877 1395  800]\n",
      " [ 974  990 1121]]\n",
      "Classification TEST DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.00      0.00      0.00        20\n",
      "       Right       0.00      0.00      0.00        20\n",
      "        Feet       0.33      1.00      0.50        20\n",
      "\n",
      "    accuracy                           0.33        60\n",
      "   macro avg       0.11      0.33      0.17        60\n",
      "weighted avg       0.11      0.33      0.17        60\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[ 0  0 20]\n",
      " [ 0  0 20]\n",
      " [ 0  0 20]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "AllBCIClass.classifyCSP_LDA(combined_epochs, target_subjects= target_data, calibrate_data= target_data_0, condition = \"noEA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# noEA + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Best parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Best cross-validation score: 0.427\n",
      "Classification TRAIN DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.43      0.58      0.49      3113\n",
      "       Right       0.45      0.42      0.44      3072\n",
      "        Feet       0.46      0.33      0.38      3085\n",
      "\n",
      "    accuracy                           0.44      9270\n",
      "   macro avg       0.45      0.44      0.44      9270\n",
      "weighted avg       0.45      0.44      0.44      9270\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[1820  705  588]\n",
      " [1208 1286  578]\n",
      " [1239  842 1004]]\n",
      "Classification TEST DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       1.00      0.05      0.10        20\n",
      "       Right       0.33      0.05      0.09        20\n",
      "        Feet       0.36      1.00      0.53        20\n",
      "\n",
      "    accuracy                           0.37        60\n",
      "   macro avg       0.56      0.37      0.24        60\n",
      "weighted avg       0.56      0.37      0.24        60\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[ 1  2 17]\n",
      " [ 0  1 19]\n",
      " [ 0  0 20]]\n"
     ]
    }
   ],
   "source": [
    "if train_svm == True:\n",
    "    AllBCIClass.classifyCSP_SVM(combined_epochs, target_subjects= target_data, calibrate_data= target_data_0,condition = \"noEA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EA + LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Classification TRAIN DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.49      0.51      0.50      3113\n",
      "       Right       0.47      0.48      0.48      3072\n",
      "        Feet       0.49      0.46      0.47      3085\n",
      "\n",
      "    accuracy                           0.48      9270\n",
      "   macro avg       0.48      0.48      0.48      9270\n",
      "weighted avg       0.48      0.48      0.48      9270\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[1583  805  725]\n",
      " [ 837 1486  749]\n",
      " [ 820  861 1404]]\n",
      "Classification TEST DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.48      0.55      0.51        20\n",
      "       Right       0.62      0.40      0.48        20\n",
      "        Feet       0.46      0.55      0.50        20\n",
      "\n",
      "    accuracy                           0.50        60\n",
      "   macro avg       0.52      0.50      0.50        60\n",
      "weighted avg       0.52      0.50      0.50        60\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[11  4  5]\n",
      " [ 4  8  8]\n",
      " [ 8  1 11]]\n"
     ]
    }
   ],
   "source": [
    "AllBCIClass.classifyCSP_LDA(combined_epochs, target_subjects= target_data, calibrate_data= target_data_0, condition = \"EA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EA + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Computing rank from data with rank='info'\n",
      "    MAG: rank 5 after 0 projectors applied to 5 channels\n",
      "Reducing data rank from 5 -> 5\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Best parameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Best cross-validation score: 0.483\n",
      "Classification TRAIN DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.51      0.51      0.51      3113\n",
      "       Right       0.49      0.49      0.49      3072\n",
      "        Feet       0.49      0.49      0.49      3085\n",
      "\n",
      "    accuracy                           0.50      9270\n",
      "   macro avg       0.50      0.50      0.50      9270\n",
      "weighted avg       0.50      0.50      0.50      9270\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[1578  768  767]\n",
      " [ 771 1504  797]\n",
      " [ 773  797 1515]]\n",
      "Classification TEST DATA \n",
      "=======================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Left       0.50      0.55      0.52        20\n",
      "       Right       0.67      0.30      0.41        20\n",
      "        Feet       0.41      0.60      0.49        20\n",
      "\n",
      "    accuracy                           0.48        60\n",
      "   macro avg       0.53      0.48      0.48        60\n",
      "weighted avg       0.53      0.48      0.48        60\n",
      "\n",
      "Confusion matrix \n",
      "=======================\n",
      "[[11  2  7]\n",
      " [ 4  6 10]\n",
      " [ 7  1 12]]\n"
     ]
    }
   ],
   "source": [
    "if train_svm == True:\n",
    "    AllBCIClass.classifyCSP_SVM(combined_epochs, target_subjects= target_data, calibrate_data= target_data_0,condition = \"EA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save wLTL weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del CSP2D_Epoch[target_data]\n",
    "# del CSP2D_Epoch[target_data_0]\n",
    "\n",
    "# # Save the dictionary\n",
    "# with open('noEA_wLTL_LR.pkl', 'wb') as file:\n",
    "#     pickle.dump(CSP2D_Epoch, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
